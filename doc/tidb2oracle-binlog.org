* Architure
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.00.png]]
 + The pump node is single node. If the node is crushed and lose the disk, have to re-copy all the data and start the incremental sync again.
 + This solution does not support the DDL change. If there is any DDL change, have to bring the service down.
 + The pump and drainer has to access the PD to fetch the data. If we deploy the TiDB cluster in the kubernetes. The pump and drainer has to been deployed into the kubernetes as well.
 + If the drainer is deployed with the TiDB cluster, the sync performance will be impacted a lot since the queries are sent to the downstream oracle server.
* Deploy TiDB to Oracle (binlog)
** Check the cluster resource using the below command
#+BEGIN_SRC
$./bin/aws tidb2ora list demo-tidb2ora-binlog
#+END_SRC

#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.01.png]]

** Prepare the yaml config file
   Please follow the [[../embed/examples/aws/tidb2ora-binlog.yaml][below example]] to prepare the yaml file with which we deploy all the components.
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.02.png]]

** Deploy required resource
  + AWS resources
    - TiDB Cluster EC2 nodes
    - Drainer node
    - Oracle RDS
    - Connect all the through transit gateway
  + Deploy TiDB Cluster
  + Deploy Drainer node
    - Oracle client install
    - TiDB binary(drainer) install
    - Drainer config file
    - Drainer service file
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.03.png]]
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.04.png]]
** List all the AWS resources
   + VPC
   + Subnet
   + Route table
   + Security Group
   + EC2
   + Oracle instance
   + Transit gateway
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.05.png]]
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.06.png]]
** Login the workstation to check the TiDB cluster status
   The TiDB cluster is deployed in the AWS. Login the workstation to check the TiDB cluster status using [tiup display] command
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.07.png]]
** Check the drainer service
   Login to drainer through workstation to check the drainer service.
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.08.png]]
** Login oracle to check no data in the test01 table
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.09.png]]
** Login TiDB to insert one record to test01
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.10.png]]
** Confirm the data's replication
#+attr_html: :width 1000px
#+attr_latex: :width 1000px
[[./png/tidb2ora-binlog/tidb2ora-binlog.11.png]]

* TiDB Nodes preparation
  #+BEGIN_SRC
$workstation:
  imageid: ami-07d02ee1eeb0c996c
  keyname: jay-us-east-01
  keyfile: /home/pi/.ssh/jay-us-east-01.pem
aws_topo_configs:
  general:
    # debian os
    imageid: ami-07d02ee1eeb0c996c
    name: tisamplenodes
    keyname: jay-us-east-01
    keyfile: /home/pi/.ssh/jay-us-east-01.pem
    cidr: 172.83.0.0/16
    instance_type: m5.2xlarge
    tidb_version: v5.4.0
  pd:
    instance_type: m5.2xlarge
    count: 3
  tidb:
    instance_type: m5.2xlarge
    count: 2
  tikv:
    instance_type: m5.2xlarge
    count: 3
  ticdc:
    instance_type: t2.micro
    count: 1

$ ./bin/aws tidb2ms deploy demo-tidb /tmp/aws-nodes-tidb.yaml
Please confirm your topology:
AWS Region:      Tokyo
Cluster type:    tidb
Cluster name:    demo-tidb
Cluster version: v5.1.0
User Name:       admin
Key Name:        jay

Component    # of nodes  Instance Type  Image Name             CIDR           User
---------    ----------  -------------  ----------             ----           ----
Workstation  1           m5.2xlarge     ami-0ac97798ccf296e02  172.82.0.0/16  admin
TiDB         2           m5.2xlarge     ami-07d02ee1eeb0c996c  172.83.0.0/16  master
PD           3           m5.2xlarge     ami-07d02ee1eeb0c996c  172.83.0.0/16  master
TiKV         3           m5.2xlarge     ami-07d02ee1eeb0c996c  172.83.0.0/16  master
TiCDC        1           t2.micro       ami-07d02ee1eeb0c996c  172.83.0.0/16  master
Attention:
    1. If the topology is not what you expected, check your yaml file.
    2. Please confirm there is no port/directory conflicts in same host.
Do you want to continue? [y/N]: (default=N) y

  #+END_SRC

* Oracle Install
  #+BEGIN_SRC
$ sqlplus admin/1234Abcd@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=tidbsync.cxmxisy1o2a2.us-east-1.rds.amazonaws.com)(Port=1521))(CONNECT_DATA=(SID=orcl)))
sqlplus$ create user test  identified by findpt account unlock default tablespace users;
grant resource,connect to test;
SQL> alter user test quota unlimited on users;
  #+END_SRC


* Note
** How to install oracle client
   https://www.geeksforgeeks.org/how-to-install-sqlplus-on-linux/

** Drainer
   https://tidb.net/blog/54bba63d
   https://docs.google.com/document/d/1e6MR0ckSCQPf0eb-untgYaemV08ZHRraUQ4NjJnVZLU/edit

 https://download.pingcap.org/tidb-v6.0.0-linux-amd64.tar.gz
* DEBUG
  [2022/05/09 10:05:59.786 +00:00] [ERROR] [binloginfo.go:248] ["write binlog failed"] [binlog_type=Prewrite] [binlog_start_ts=433085666993111041] [binlog_commit_ts=0] [error="write binlog failed, the last error rpc error: code = DeadlineExceeded desc = context deadline exceeded"]

  server_configs:
  tidb: 
    binlog.enable: true
    binlog.ignore-error: false

* Todo
  + Install the TiDB on the nodes including Pump and Drainer(Done
  + Install the Oracle Client on the Drainer node
  + Install the Drainer on the Drainer node
  + Performance test
** tidb client install
#+BEGIN_SRC
$ sudo apt-get install -y mariadb-server
$ mysql> use test;
$ mysql> create table test01(col01 int primary key, col02 int );
#+END_SRC
    
** tidb binary install
#+BEGIN_SRC
$ sudo apt-get update -y
$ wget https://download.pingcap.org/tidb-v6.0.0-linux-amd64.tar.gz
$ tar xvf tidb-v6.0.0-linux-amd64.tar.gz
$ scp -r tidb-v6.0.0-linux-amd64 172.83.1.138:/tmp/
$ ssh 172.83.1.138 'sudo mv /tmp/tidb-v6.0.0-linux-amd64 /opt/'
#+END_SRC

** SQLPLUS binary install
#+BEGIN_SRC
$ wget https://download.oracle.com/otn_software/linux/instantclient/214000/instantclient-basic-linux.x64-21.4.0.0.0dbru.zip
$ wget https://download.oracle.com/otn_software/linux/instantclient/214000/instantclient-sqlplus-linux.x64-21.4.0.0.0dbru.zip
$ ssh 172.83.1.138 'sudo mkdir -p /opt/oracle'
$ sudo apt-get install -y zip
$ unzip instantclient-basic-linux.x64-21.4.0.0.0dbru.zip
$ unzip instantclient-sqlplus-linux.x64-21.4.0.0.0dbru.zip
$ scp -r instantclient_21_4 172.83.1.138:/tmp/
$ ssh 172.83.1.138 'sudo rm -rf /opt/oracle/instantclient_21_4'
$ ssh 172.83.1.138 'sudo mv /tmp/instantclient_21_4 /opt/oracle'
#+END_SRC

** Oracle resource
#+BEGIN_SRC
sqlplus> create user test identified by test account unlock default tablespace users;
sqlplus> grant resource,connect to test;
sqlplus> alter user test quota unlimited on users;
sqlplus> create table test.test01(col01 int primary key, col02 int);
sqlplus> create or replace procedure do_truncate(table_name     in varchar2,
                                          partition_name in varchar2) as
begin
  if partition_name || 'x' = 'x' then
    execute immediate 'truncate table ' || table_name;
  else
    execute immediate 'alter table ' || table_name || ' truncate partition ' || partition_name;
  end if;
end;
/

#+END_SRC

** Set the variable for SQLPLUS
#+BEGIN_SRC
export LD_LIBRARY_PATH=/opt/oracle/instantclient_21_4:$LD_LIBRARY_PATH
export PATH=$LD_LIBRARY_PATH:$PATH
#+END_SRC

** Set envoronment variable for tidb
#+BEGIN_SRC
export PATH=/opt/tidb-v6.0.0-linux-amd64/bin:$PATH
#+END_SRC

* Memo
If the disk of pump is too small, it cause the disk failure.

