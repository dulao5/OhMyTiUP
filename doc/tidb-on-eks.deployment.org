#+OPTIONS: \n:t
#+OPTIONS: ^:nil
#+TITLE: TiDB deployment on EKS
* Architure
  #+CAPTION: workstation preparation 01
  #+ATTR_HTML: :width 800 :style border:2px solid black;
  [[./png/tidb-on-eks/architecture.eks.png]]
  
* workstation setup
*** Workstation creation by stack
    Please refer to [[https://s3.ap-northeast-1.amazonaws.com/tidb.cloudformation.template/common/workstation.yaml][workstation cloudformation template]] to create the workstation.
#+CAPTION: workstation preparation 01
#+ATTR_HTML: :width 800 :style border:2px solid black;
[[./png/tidb-on-eks/01.workstation.01.png]]
#+CAPTION: workstation preparation 02
#+ATTR_HTML: :width 800 :style border:2px solid black;
[[./png/tidb-on-eks/01.workstation.02.png]]
#+CAPTION: workstation preparation 03
#+ATTR_HTML: :width 800 :style border:2px solid black;
[[./png/tidb-on-eks/01.workstation.03.png]]
*** AWS config
    Login to the workstation and setup the aws cli (Please refer to [[https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html][AWS Configuration Basis]] for setup).
*** eksctl and kubectl installation
    Please refer to [[https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html][Getting started with Amazon EKS -eksctl]] to install the eksctl and kubectl in the workstation.
    #+BEGIN_SRC shell
admin@ip-172-81-11-52:~$ curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.21.2/2021-07-05/bin/linux/amd64/kubectl
admin@ip-172-81-11-52:~$ chmod 755 kubectl
admin@ip-172-81-11-52:~$ sudo mv kubectl /usr/local/bin/
admin@ip-172-81-11-52:~$ kubectl version --short --client
Client Version: v1.21.2-13+d2965f0db10712
admin@ip-172-81-11-52:~$ curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
admin@ip-172-81-11-52:~$ sudo mv /tmp/eksctl /usr/local/bin/
admin@ip-172-81-11-52:~$ eksctl version
0.82.0
    #+END_SRC
*** helm installation
    Please refer to [[https://helm.sh/docs/intro/install/][Helm installation]]
    #+BEGIN_SRC
admin@ip-172-81-11-52:~$ curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
admin@ip-172-81-11-52:~$ chmod 700 get_helm.sh
admin@ip-172-81-11-52:~$ ./get_helm.sh
bash: warning: setlocale: LC_ALL: cannot change locale (ja_JP.UTF-8)
Downloading https://get.helm.sh/helm-v3.8.0-linux-amd64.tar.gz
Verifying checksum... Done.
Preparing to install helm into /usr/local/bin
helm installed into /usr/local/bin/helm
admin@ip-172-81-11-52:
admin@ip-172-81-11-52:~$ helm version 
version.BuildInfo{Version:"v3.8.0", GitCommit:"d14138609b01886f544b2025f5000351c9eb092e", GitTreeState:"clean", GoVersion:"go1.17.5"}
    #+END_SRC
*** aws-ami-authenticator
    Please refer to [[https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html][aws-iam-authenticator]]
    #+BEGIN_SRC
admin@ip-172-81-11-52:~$ curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.21.2/2021-07-05/bin/linux/amd64/aws-iam-authenticator
admin@ip-172-81-11-52:~$ chmod +x ./aws-iam-authenticator
admin@ip-172-81-11-52:~$ sudo mv aws-iam-authenticator /usr/local/bin/
admin@ip-172-81-11-52:~$ aws-iam-authenticator version   
{"Version":"v0.5.0","Commit":"1cfe2a90f68381eacd7b6dcfa2bf689e76eb8b4b"}
    #+END_SRC
* EKS setup
   Please refer to [[https://docs.pingcap.com/tidb-in-kubernetes/stable/deploy-on-aws-eks][deploy-on-aws-eks]]. Now let's have your cup of coffee for a rest until the aws resources are completed.
   
   #+BEGIN_SRC
admin@ip-172-81-11-52:~$ more eks.cluster.yaml
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig
metadata:
  name: tidb2cloudcdc
  region: ap-northeast-1

nodeGroups:
  - name: admin
    desiredCapacity: 1
    privateNetworking: true
    labels:
      dedicated: admin

  - name: tidb-1a
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1a"]
    instanceType: c5.2xlarge
    labels:
      dedicated: tidb
    taints:
      dedicated: tidb:NoSchedule
  - name: tidb-1d
    desiredCapacity: 0
    privateNetworking: true
    availabilityZones: ["ap-northeast-1d"]
    instanceType: c5.2xlarge
    labels:
      dedicated: tidb
    taints:
      dedicated: tidb:NoSchedule
  - name: tidb-1c
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1c"]
    instanceType: c5.2xlarge
    labels:
      dedicated: tidb
    taints:
      dedicated: tidb:NoSchedule

  - name: pd-1a
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1a"]
    instanceType: c5.xlarge
    labels:
      dedicated: pd
    taints:
      dedicated: pd:NoSchedule
  - name: pd-1d
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1d"]
    instanceType: c5.xlarge
    labels:
      dedicated: pd
    taints:
      dedicated: pd:NoSchedule
  - name: pd-1c
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1c"]
    instanceType: c5.xlarge
    labels:
      dedicated: pd
    taints:
      dedicated: pd:NoSchedule

  - name: tikv-1a
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1a"]
    instanceType: r5b.2xlarge
    labels:
      dedicated: tikv
    taints:
      dedicated: tikv:NoSchedule
  - name: tikv-1d
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1d"]
    instanceType: r5b.2xlarge
    labels:
      dedicated: tikv
    taints:
      dedicated: tikv:NoSchedule
  - name: tikv-1c
    desiredCapacity: 1
    privateNetworking: true
    availabilityZones: ["ap-northeast-1c"]
    instanceType: r5b.2xlarge
    labels:
      dedicated: tikv
    taints:
      dedicated: tikv:NoSchedule
admin@ip-172-81-11-52:~$ eksctl create cluster -f eks.cluster.yaml
2022-02-06 11:59:25   eksctl version 0.82.0
... ...
2022-02-06 12:17:37   saved kubeconfig as "/home/admin/.kube/config"
2022-02-06 12:17:37   no tasks
2022-02-06 12:17:37   all EKS cluster resources for "tidb2cloudcdc" have been created
... ...
2022-02-06 12:24:52   kubectl command should work with "/home/admin/.kube/config", try 'kubectl get nodes'
2022-02-06 12:24:52   EKS cluster "tidb2cloudcdc" in "ap-northeast-1" region is ready
admin@ip-172-81-11-52:~$
admin@ip-172-81-11-52:~$ eksctl get nodegroup --cluster tidb2cloudcdc
CLUSTER        NODEGROUP       STATUS          CREATED                 MIN SIZE        MAX SIZE        DESIRED CAPACITY        INSTANCE TYPE   IMAGE ID
tidb2cloudcdc  admin           CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       m5.large        ami-0b49509d917c6649b
tidb2cloudcdc  pd-1a           CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       c5.xlarge       ami-0b49509d917c6649b
tidb2cloudcdc  pd-1c           CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       c5.xlarge       ami-0b49509d917c6649b
tidb2cloudcdc  pd-1d           CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       c5.xlarge       ami-0b49509d917c6649b
tidb2cloudcdc  tidb-1a         CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       c5.2xlarge      ami-0b49509d917c6649b
tidb2cloudcdc  tidb-1c         CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       c5.2xlarge      ami-0b49509d917c6649b
tidb2cloudcdc  tidb-1d         CREATE_COMPLETE 2022-02-06T12:13:29Z    0               0               0                       c5.2xlarge      ami-0b49509d917c6649b
tidb2cloudcdc  tikv-1a         CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       r5b.2xlarge     ami-0b49509d917c6649b
tidb2cloudcdc  tikv-1c         CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       r5b.2xlarge     ami-0b49509d917c6649b
tidb2cloudcdc  tikv-1d         CREATE_COMPLETE 2022-02-06T12:13:29Z    1               1               1                       r5b.2xlarge     ami-0b49509d917c6649b
   #+END_SRC

** TiDB Cluster operator installation
   Please refer to [[https://docs.pingcap.com/tidb-in-kubernetes/stable/get-started#step-2-deploy-tidb-operator][Deploy TiDB Operator]]
   #+BEGIN_SRC
admin@ip-172-81-11-52:~$ kubectl apply -f https://raw.githubusercontent.com/pingcap/tidb-operator/v1.2.4/manifests/crd.yaml
Warning: apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
customresourcedefinition.apiextensions.k8s.io/tidbclusters.pingcap.com created
customresourcedefinition.apiextensions.k8s.io/dmclusters.pingcap.com created
customresourcedefinition.apiextensions.k8s.io/backups.pingcap.com created
customresourcedefinition.apiextensions.k8s.io/restores.pingcap.com created
customresourcedefinition.apiextensions.k8s.io/backupschedules.pingcap.com created
customresourcedefinition.apiextensions.k8s.io/tidbmonitors.pingcap.com created
customresourcedefinition.apiextensions.k8s.io/tidbinitializers.pingcap.com created
customresourcedefinition.apiextensions.k8s.io/tidbclusterautoscalers.pingcap.com created
admin@ip-172-81-11-52:~$ helm repo add pingcap https://charts.pingcap.org/
"pingcap" has been added to your repositories
admin@ip-172-81-11-52:~$ kubectl create namespace tidb-admin
namespace/tidb-admin created
admin@ip-172-81-11-52:~$ helm install --namespace tidb-admin tidb-operator pingcap/tidb-operator --version v1.2.6
NAME: tidb-operator
LAST DEPLOYED: Sun Feb  6 12:32:57 2022
NAMESPACE: tidb-admin
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Make sure tidb-operator components are running:

    kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator

admin@ip-172-81-11-52:~$ kubectl get pods --namespace tidb-admin -l app.kubernetes.io/instance=tidb-operator
NAME                                       READY   STATUS    RESTARTS   AGE
tidb-controller-manager-56b57bf6c5-hmtbm   1/1     Running   0          34s
tidb-scheduler-7f8cc67d78-pq5c4            2/2     Running   0          34s
   #+END_SRC
** TiDB Cluster setup
   Please refer to [[https://docs.pingcap.com/tidb-in-kubernetes/stable/deploy-on-aws-eks][deploy-on-aws-eks]]
   #+BEGIN_SRC
admin@ip-172-81-11-52:~$ kubectl create namespace tidb-cluster
namespace/tidb-cluster created
admin@ip-172-81-11-52:~$ curl -O https://raw.githubusercontent.com/pingcap/tidb-operator/master/examples/aws/tidb-cluster.yaml
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  3004  100  3004    0     0  13779      0 --:--:-- --:--:-- --:--:-- 13716
admin@ip-172-81-11-52:~$ curl -O https://raw.githubusercontent.com/pingcap/tidb-operator/master/examples/aws/tidb-monitor.yaml
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  1639  100  1639    0     0   7552      0 --:--:-- --:--:-- --:--:--  7552
admin@ip-172-81-11-52:~$ kubectl apply -f tidb-cluster.yaml -n tidb-cluster 
tidbcluster.pingcap.com/basic created
admin@ip-172-81-11-52:~$ kubectl apply -f tidb-monitor.yaml -n tidb-cluster
tidbmonitor.pingcap.com/basic created
admin@ip-172-81-11-52:~$ kubectl get pods -n tidb-cluster 
NAME                               READY   STATUS    RESTARTS   AGE
basic-discovery-6fb89f458c-8x6cg   1/1     Running   0          2m30s
basic-monitor-0                    3/3     Running   0          2m6s
basic-pd-0                         1/1     Running   0          2m30s
basic-pd-1                         1/1     Running   0          2m30s
basic-pd-2                         1/1     Running   0          2m29s
basic-tidb-0                       2/2     Running   0          44s
basic-tidb-1                       2/2     Running   0          44s
basic-tikv-0                       1/1     Running   0          87s
basic-tikv-1                       1/1     Running   0          87s
basic-tikv-2                       1/1     Running   0          87s
admin@ip-172-81-11-52:~$ kubectl get service -n tidb-cluster 
NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP                                                                          PORT(S)                          AGE
basic-discovery          ClusterIP      10.100.166.42   <none>                                                                               10261/TCP,10262/TCP              2m57s
basic-grafana            LoadBalancer   10.100.91.214   ac456684a300244be8e8c4d19e228d52-ddbfb659f9296b3c.elb.ap-northeast-1.amazonaws.com   3000:31601/TCP                   2m34s
basic-monitor-reloader   NodePort       10.100.123.67   <none>                                                                               9089:32115/TCP                   2m34s
basic-pd                 ClusterIP      10.100.226.81   <none>                                                                               2379/TCP                         2m57s
basic-pd-peer            ClusterIP      None            <none>                                                                               2380/TCP                         2m57s
basic-prometheus         NodePort       10.100.166.52   <none>                                                                               9090:30872/TCP                   2m34s
basic-tidb               LoadBalancer   10.100.195.98   ac8985bb5178c4b898d9fc8024d30a8d-baf9ea7b93667dc7.elb.ap-northeast-1.amazonaws.com   4000:31174/TCP,10080:30152/TCP   71s
basic-tidb-peer          ClusterIP      None            <none>                                                                               10080/TCP                        71s
basic-tikv-peer          ClusterIP      None            <none>                                                                               20160/TCP                        114s

   #+END_SRC
** VPC peering setup and test connectivity
*** VPC peering setup
    #+CAPTION: VPC peering setup between workstation and eks
    #+ATTR_HTML: :width 800 :style border:2px solid black;
    [[./png/tidb-on-eks/02.vpc.peering.png]]
*** Route addition on workstation
    #+CAPTION: Set route rule in workstation to access eks
    #+ATTR_HTML: :width 800 :style border:2px solid black;
    [[./png/tidb-on-eks/03.route.01.png]]
*** Route addition on eks
    There are three route tables for each subnet in the eks VPC. Need to add the rule to all the route tables.
    #+CAPTION: Set route rule in eks to access workstation
    #+ATTR_HTML: :width 800 :style border:2px solid black;
    [[./png/tidb-on-eks/03.route.02.png]]
    #+CAPTION: Set route rule in eks to access workstation
    #+ATTR_HTML: :width 800 :style border:2px solid black;
    [[./png/tidb-on-eks/03.route.03.png]]    
*** Test the contivity between workstation and TiDB
    Use kubectl to get all the services, in which find out the LoadBalancer server for tidb and use it as the host to connect to.
#+BEGIN_SRC
admin@ip-172-81-11-52:~$ sudo apt-get -y update
admin@ip-172-81-11-52:~$ sudo apt-get install -y mariadb-client
admin@ip-172-81-11-52:~$ kubectl get service -n tidb-cluster 
NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP                                                                          PORT(S)                          AGE
basic-discovery          ClusterIP      10.100.166.42   <none>                                                                               10261/TCP,10262/TCP              26m
basic-grafana            LoadBalancer   10.100.91.214   ac456684a300244be8e8c4d19e228d52-ddbfb659f9296b3c.elb.ap-northeast-1.amazonaws.com   3000:31601/TCP                   26m
basic-monitor-reloader   NodePort       10.100.123.67   <none>                                                                               9089:32115/TCP                   26m
basic-pd                 ClusterIP      10.100.226.81   <none>                                                                               2379/TCP                         26m
basic-pd-peer            ClusterIP      None            <none>                                                                               2380/TCP                         26m
basic-prometheus         NodePort       10.100.166.52   <none>                                                                               9090:30872/TCP                   26m
basic-tidb               LoadBalancer   10.100.195.98   ac8985bb5178c4b898d9fc8024d30a8d-baf9ea7b93667dc7.elb.ap-northeast-1.amazonaws.com   4000:31174/TCP,10080:30152/TCP   24m
basic-tidb-peer          ClusterIP      None            <none>                                                                               10080/TCP                        24m
basic-tikv-peer          ClusterIP      None            <none>                                                                               20160/TCP                        25m

admin@ip-172-81-11-52:~$ mysql -h ac8985bb5178c4b898d9fc8024d30a8d-baf9ea7b93667dc7.elb.ap-northeast-1.amazonaws.com -u root -P 4000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 307
Server version: 5.7.25-TiDB-v5.3.0 TiDB Server (Apache License 2.0) Community Edition, MySQL 5.7 compatible

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MySQL [(none)]> 

#+END_SRC



* Reference
#+BEGIN_SRC
admin@ip-172-81-11-14:/DATA$ time aws s3 cp s3://tidbdata/data/test.ontime.000000000.sql ./
download: s3://tidbdata/data/test.ontime.000000000.sql to ./test.ontime.000000000.sql

real    11m36.388s
user    3m11.385s
sys     2m27.900s
admin@ip-172-81-11-14:/DATA$ ls -alrth test.ontime.000000000.sql
-rw-r--r-- 1 admin admin 32G Feb  9 11:51 test.ontime.000000000.sql
#+END_SRC
